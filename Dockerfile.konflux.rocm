## Global Args #################################################################
ARG RHAIIS_VERSION=3.2.1

## Base Layer ##################################################################
FROM registry.redhat.io/rhaiis/vllm-rocm-rhel9:${RHAIIS_VERSION} as vllm-grpc-adapter

ARG VLLM_TGIS_ADAPTER_VERSION="0.9.0.post1"
USER root

## Build vLLM-TGIS-Adapter from source #########################################
RUN pip install --no-cache-dir --no-deps git+https://github.com/opendatahub-io/vllm-tgis-adapter@${VLLM_TGIS_ADAPTER_VERSION}

USER 1001

ENV GRPC_PORT=8033 \
    PORT=8000 \
    # As an optimization, vLLM disables logprobs when using spec decoding by
    # default, but this would be unexpected to users of a hosted model that
    # happens to have spec decoding
    # see: https://github.com/vllm-project/vllm/pull/6485
    DISABLE_LOGPROBS_DURING_SPEC_DECODING=false


ENTRYPOINT ["python3", "-m", "vllm_tgis_adapter", "--uvicorn-log-level=warning"]

LABEL name="rhoai/odh-vllm-rocm-rhel9" \
      com.redhat.component="odh-vllm-rocm-rhel9" \
      io.k8s.display-name="odh-vllm-rocm-rhel9" \
      io.k8s.description="GPU-accelerated vLLM build using AMD ROCm for high-performance inference." \
      description="GPU-accelerated vLLM build using AMD ROCm for high-performance inference." \
      summary="GPU-accelerated vLLM build using AMD ROCm for high-performance inference." \
      com.redhat.license_terms="https://www.redhat.com/licenses/Red_Hat_Standard_EULA_20191108.pdf"

